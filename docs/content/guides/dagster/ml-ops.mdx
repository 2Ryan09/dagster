---
title: Building machine learning pipelines In Dagster | Dagster Docs
description: This guide illustrates how to use Dagster to operationaize your machine learning pipeline
---

# Building machine learning pipelines with Dagster

In this guide, weâ€™ll walk you through how to take your machine learning models and deploy and mantain them in production using Dagster, reliably and efficently.

We will work through several aspects of MLOps, including using assets for different elements of your machine learning pipeline, how to automate model training, and monitoring your model's drift.

---

## Why build your ML pipelines with Dagster?

- Dagster makes iterating on machine learning models and testing easy and it is designed to use during the development process.
- Dagster has a lightweight execution model means you can access the benefits of an orchestrator, like re-executing from the middle of a pipeline and parallelizing steps while you're experimenting.
- Dagster models data assets, not just tasks, so it understands the upstream and downstream data dependencies.
- Dagster is one-stop shop for both the data transformations and the models that depend on the data transformations!

<Note>
  This guide assumes you have familiarity with machine learning concepts and several Dagster concepts,
  including{" "}
  <a href="/concepts/assets/software-defined-assets">software-defined assets</a>{" "}
  and <a href="/concepts/ops-jobs-graphs/jobs">jobs</a> . We also recommend
  reviewing the{" "}
  <a href="/guides/dagster/automating-pipelines">
    Automating Data Pipelines guide
  </a>{" "}
  as many of the same principles can be applied to Machine Learning Operations (MLOps).
</Note>

---
## Machine learning development

If you are already using Dagster for your ETL pipelines, it is a natural progression to build out and test your models in Dagster.

For this guide, we will be using the Hacker News data demoed in the [tutorial](/tutorial).

The machine learning model we will walk through takes the Hacker News stories and uses the titles to predict the number of comments that a story will generate. This will be a supervised model since we have the number of comments for all the previous stories.

The assets graph will look like this at the end of this guide:

<Image
alt="alt"
src="/images/guides/ml-ops/ml_asset_dag.png"
width={1804}
height={1064}
/>

### Ingesting Data

First, we will be creating an asset which retrieves the latest 1000 hackernews records.

```python file=/guides/dagster/ml_ops/ml_ops.py startafter=data_ingestion_start endbefore=data_ingestion_end
import requests
from dagster import asset, FreshnessPolicy
import pandas as pd

@asset(freshness_policy=FreshnessPolicy(maximum_lag_minutes=10))
def hackernews_stories():
    """Get the max ID number from hacker news"""
    latest_item = requests.get(
        f"https://hacker-news.firebaseio.com/v0/maxitem.json"
    ).json()
    """Get items based on story ids from the HackerNews items endpoint"""
    results = []
    scope = range(latest_item-1000, latest_item)
    for item_id in scope:
        item = requests.get(
            f"https://hacker-news.firebaseio.com/v0/item/{item_id}.json"
        ).json()
        results.append(item)

    df = pd.DataFrame(results)
    if len(df) > 0:
        df = df[df.type == "story"]
        df = df[~df.title.isna()]

    return df
```

### Transforming data

Now that we have a dataframe with all valid stories, we want to transform that data into something our machine learning model will be able to use.

The first step is taking the dataframe and splitting into a [training and test set](https://en.wikipedia.org/wiki/Training,\_validation,\_and_test_data_sets). In some of your models, you also might choose to have an additional split for a validation set. The reason we split the data is so that we can have a test and/or a validation dataset that is independent of the training set. We can then use that dataset to see how well our model did.

```python file=/guides/dagster/ml_ops/ml_ops.py startafter=test_train_split_start endbefore=test_train_split_end
from sklearn.model_selection import train_test_split
from dagster import multi_asset, AssetOut

@multi_asset(outs={'training_data': AssetOut(), 'test_data': AssetOut()})
def training_test_data(hackernews_stories):
    hackernews_stories = hackernews_stories
    X = hackernews_stories.title
    y = hackernews_stories.descendants
    """Split the dataset to reserve 20% of records as the test set"""
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
    return (X_train,  y_train), (X_test, y_test)
```

Next, we will take both the training and test data subsets and [tokenize the titles](https://en.wikipedia.org/wiki/Lexical_analysis) e.g. take the words and turn them into columns with the frequency of terms for each records to create [features](https://en.wikipedia.org/wiki/Feature_\(machine_learning\)) for the data. To do this, we will be using the training set to fit the tokenizer, in this case we are using [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) and then transforming both the training and test set based with that tokenizer.

```python file=/guides/dagster/ml_ops/ml_ops.py startafter=vectorizer_start endbefore=vectorizer_end
from sklearn.feature_extraction.text import TfidfVectorizer
import numpy as np

@multi_asset(outs={'Tfidf_Vectorizer': AssetOut(), 'transformed_training_data': AssetOut()})
def transformed_train(training_data):
    X_train,  y_train = training_data
    """Initiate and fit the tokenizer on the training data and transform the training dataset"""
    vectorizer = TfidfVectorizer()
    transformed_X_train = vectorizer.fit_transform(X_train)
    transformed_X_train = transformed_X_train.toarray()
    y_train = y_train.fillna(0)
    transformed_y_train = np.array(y_train)
    return vectorizer, (transformed_X_train, transformed_y_train)

@asset
def transformed_test_data(test_data, Tfidf_Vectorizer):
    X_test, y_test = test_data
    """Use the fitted tokenizer to transform the test dataset"""
    transformed_X_test = Tfidf_Vectorizer.transform(X_test)
    transformed_y_test = np.array(y_test)
    y_test = y_test.fillna(0)
    transformed_y_test = np.array(y_test)
    return transformed_X_test, transformed_y_test
```

We also transformed the dataframes into NumPy arrays and removed <PyObject object="nan"/> values to prepare the data for training.


### Training the model

At this point, we have <PyObject object="X_train"/>, <PyObject object="y_train"/>, <PyObject object="X_test"/>, and <PyObject object="y_test"/> ready to go for our model. To train our model, we can use any number of models from libraries like [sklearn](https://scikit-learn.org/), [tensorflow](https://www.tensorflow.org/), and [pytorch](https://pytorch.org/).

In our example, we will train an [XGBoost model](https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.XGBRegressor) to predict a numerical value.

```python file=/guides/dagster/ml_ops/ml_ops.py startafter=models_start endbefore=models_end
import xgboost as xg
from sklearn.metrics import mean_absolute_error

@asset
def xgboost(transformed_training_data):
    transformed_X_train, transformed_y_train = transformed_training_data
    """Train XGBoost model, which is a highly efficent and flexible model"""
    xgb_r = xg.XGBRegressor(objective ='reg:squarederror', eval_metric=mean_absolute_error,
                  n_estimators = 20)
    xgb_r.fit(transformed_X_train, transformed_y_train)
    return xgb_r

@asset
def score_xgboost( transformed_test_data, xgboost):
    transformed_X_test, transformed_y_test = transformed_test_data
    """Use the test set data to get a score of the XGBoost model"""
    score = xgboost.score(transformed_X_test, transformed_y_test)
    return score
```

We include [freshness policies](/concepts/partitions-schedules-sensors/asset-sensors#freshness-policy-sensors) in the models here which will ensure the upstream data transformation assets are updated to comply with these policies.

### Evaluating our results

In our model assets, we evaluated each of the models on the test data and in this case, got the error between the predicted and actual results. Next, lets create an asset which runs inference on the model, more frequently than the model is re-trained to predict the results.

```python file=/guides/dagster/ml_ops/ml_ops.py startafter=inference_start endbefore=inference_end
@asset(freshness_policy=FreshnessPolicy(maximum_lag_minutes=60))
def model_inference(xgboost, Tfidf_Vectorizer):
    """Get the max ID number from hacker news"""

    latest_item = requests.get(
        f"https://hacker-news.firebaseio.com/v0/maxitem.json"
    ).json()
    """Get items based on story ids from the HackerNews items endpoint"""
    results = []
    scope = range(latest_item-100, latest_item)
    for item_id in scope:
        item = requests.get(
            f"https://hacker-news.firebaseio.com/v0/item/{item_id}.json"
        ).json()
        results.append(item)

    df = pd.DataFrame(results)
    if len(df) > 0:
        df = df[df.type == "story"]
        df = df[~df.title.isna()]
    inference_x = df.title
    inference_x = Tfidf_Vectorizer.transform(inference_x)
    return xgboost.predict(inference_x)
```

Depending on what the objective of your ML model is, you can use this data to set alerts, save model performance history and trigger retraining.

Dagster integrates with [Weights & Biases](/\_apidocs/libraries/dagster-wandb) and an [example](https://github.com/dagster-io/dagster/tree/master/examples/with_wandb) which demonstrates how to use W\&B's artifacts with Dagster.
