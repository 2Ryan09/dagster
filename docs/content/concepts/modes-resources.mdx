---
title: Resources | Dagster
description: Resources enable you to separate the pipeline logic from the environments and therefore make it easier to test and develop data pipelines in various environments.
---

# Resources

Resources are pluggable objects that can be shared by multiple solids in a pipeline.

## Relevant APIs

| Name                                                   | Description                                                                                                                                                                                                                                                                    |
| ------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| <PyObject object="PipelineDefinition" method="bind" /> | A method that creates a derived pipeline with a given set of resources.                                                                                                                                                                                                        |
| <PyObject object="resource" decorator />               | A decorator used to create resource definitions. The decorator returns a <PyObject object="ResourceDefinition" />, which invokes the decorated function to instantiate the resource.                                                                                           |
| <PyObject object="ResourceDefinition" />               | Resource definitions help defer resource instantiation until solid execution time, You almost never want to use initialize this class directly. Instead, you should use the <PyObject object="resource" decorator /> which returns a <PyObject object="ResourceDefinition" />. |

## Overview

Resources are pluggable objects that can be shared by multiple solids in a pipeline. They typically model external systems like databases, file systems, and APIs. They're often used to create different versions of the same logical pipeline, such that each version can execute in a different environment.

Solids express resource requirements, e.g. "I need a resource called `data_warehouse`", and then the pipeline containing the solids provides those resources. When defining a pipeline, you can leave some resource requirements unsatisfied and then later "bind" resources to it to derive pipeline versions that include those resources. Each version can correspond to an operating environment that the pipeline is intended for and include the set of resources for that environment. For example, the production version of a pipeline might include a resource representing a production S3 bucket, while a version for local development might use the local file system instead.

It's common to define collections of resources that correspond to particular operating environments and to share those collections across multiple pipelines.

### Requiring and using a resource

Here's a solid that needs to get data on cereals from an external service. It expects a resource that it can access with the name "cereals_source", and it invokes a method called `fetch_cereal_lines` on that resource.

```python file=/concepts/modes_resources/modes_resources.py startafter=start_solid_with_required_resource endbefore=end_solid_with_required_resource
@solid(required_resource_keys={"cereals_source"})
def load_cereals(context):
    lines = context.resource.fetch_cereal_lines()
    cereals = [row for row in csv.DictReader(lines)]
    context.log.info(f"Found {len(cereals)} cereals")
```

### Defining and supplying a resource

The simplest way to define a resource is as a plain old Python object:

```python file=/concepts/modes_resources/modes_resources.py startafter=start_resource endbefore=end_resource
class ExternalCerealsSource:
    def fetch_cereals_lines(self):
        response = requests.get("https://docs.dagster.io/assets/cereal.csv")
        return response.text.split("\n")
```

When defining a pipeline, you can make resources available to the solids inside it with the `resource_defs` argument:

```python file=/concepts/modes_resources/modes_resources.py startafter=start_pipeline endbefore=end_pipeline
@pipeline(resource_defs={"cereals_source": ExternalCerealsSource()})
def cereal_pipeline():
    load_cereals()
```

## Binding resources to a pipeline

Resources are most useful when you want to execute the same pipeline with different resources in different situations. You can define a pipeline without satisfying its resource requirements, then bind resources to it to create derived pipelines that have the same solids but different resources.

```python file=/concepts/modes_resources/modes_resources.py startafter=start_multiple_versions endbefore=end_multiple_versions
class MockCerealsSource:
    def fetch_cereals_lines(self):
        response_text = """
        name,mfr,type,calories,protein,fat,sodium,fiber,carbo,sugars,potass,vitamins,shelf,weight,cups,rating
        100% Bran,N,C,70,4,1,130,10,5,6,280,25,3,1,0.33,68.402973
        100% Natural Bran,Q,C,120,3,5,15,2,8,8,135,0,3,1,1,33.983679
        """
        return response_text.split("\n")


@pipeline
def cereal_pipeline_2():
    load_cereals()


dev_pipeline = cereal_pipeline_2.bind({"cereals_source": MockCerealsSource()}, "dev")
prod_pipeline = cereal_pipeline_2.bind({"cereals_source": ExternalCerealsSource()}, "prod")
```

A common pattern when defining multiple derived pipelines is to expose them on separate [repositories](/concepts/repositories-workspaces/repositories). Then, in your production Dagster instance, you can point to the production repository so the development versions of your pipelines don't clutter up your production Dagit.

```python file=/concepts/modes_resources/modes_resources.py startafter=start_repositories endbefore=end_repositories
from dagster import repository


@repository
def dev_repository():
    return [dev_pipeline]


@repository
def prod_repository():
    return [prod_pipeline]
```

## Advanced resource initialization

In the example above, `ExternalCerealsSource` is instantiated every time that the module is loaded. `ExternalCerealsSource`is cheap to initialize, but, in some situations, you might want to run heavy initialization logic for your resource. For example, initializing your resource might involve booting up a Spark session that connects to a set of executors on a cluster. You'd only want to do that when you actually execute your pipeline, not when Dagit loads your module to determine the pipeline's name and structure.

For cases where a resource requires heavy initialization, you can construct a resource definition. When you've constructed a resource definition, initialization happens at the time that the solid that uses it is executed, not every time the module is loaded.

### Configuring resources

TODO

### Context managers

TODO

## Using derived pipelines in Dagit and the CLI

### In Dagit

When you've navigated to a pipeline in Dagit, you can navigate to other pipelines that were derived from the same pipeline.

<Image
alt="Modes in Dagit"
src="/images/concepts/modes-resources/modes-dagit.png"
width={3808}
height={2414}
/>

### Dagster CLI

To launch a derived pipeline via the CLI, its name is the name of the pipeline it's derived from, plus its name, separated by a forward slash:

    $ dagster pipeline execute cereal_pipeline_2/prod

## Examples

### Resource Configuration

<PyObject object="ResourceDefinition" pluralize /> can have a config schema, which
allows you to customize behavior at runtime through pipeline configuration.

For example, let's say we wanted to pass a connection string to our `DatabaseConnection` resource.

```python file=/concepts/modes_resources/modes_resources.py startafter=start_resource_config endbefore=end_resource_config
class DatabaseConnection:
    def __init__(self, connection: str):
        self.connection = connection


@resource(config_schema={"connection": str})
def db_resource(init_context):
    connection = init_context.resource_config["connection"]
    return DatabaseConnection(connection)
```

### Resource to Resource Dependencies

Resources can depend upon other resources. Use the `required_resource_keys` parameter of the <PyObject object="resource" decorator/> decorator to specify which resources to depend upon. Access the required resources through the context object provided to the wrapped function.

```python file=/concepts/modes_resources/modes_resources.py startafter=start_resource_dep_example endbefore=end_resource_dep_example
@resource
def foo_resource(_):
    return "foo"


@resource(required_resource_keys={"foo"})
def emit_foo(init_context):
    return init_context.resources.foo
```

Note that the dependencies between resources cannot be cyclic.

```python file=/concepts/modes_resources/modes_resources.py startafter=start_resource_dep_mode endbefore=end_resource_dep_mode
ModeDefinition(resource_defs={"foo": foo_resource, "emit": emit_foo})
```
