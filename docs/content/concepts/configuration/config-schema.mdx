---
title: Run Configuration | Dagster
description: Pipeline run configuration allows providing parameters to pipelines at the time they're executed.
---

# Run Configuration

Pipeline run configuration allows providing parameters to pipelines at the time they're executed.

## Relevant APIs

| Name                                                 | Description                                              |
| ---------------------------------------------------- | -------------------------------------------------------- |
| <PyObject module="dagster" object="ConfigSchema"  /> | See details with code examples in the API documentation. |

## Overview

It's often useful to configure pipelines at run time. For example, you might want whoever is running a pipeline to decide what dataset it operates on. In general, you should use Dagster's config system when you want the person or software that is executing a pipeline to be able to make choices about what the pipeline does, without needing to modify the pipeline definition.

The objects that compose a pipeline - solids and resources - are each individually configurable. When executing a pipeline, you can supply "run configuration", either in the form of a YAML document or a Python dictionary, that specifies the configuration for each of the objects in the pipeline.

A common use of configuration is for a [schedule](/concepts/partitions-schedules-sensors/schedules) or [sensor](/concepts/partitions-schedules-sensors/schedules) to provide configuration to the pipeline run it is launching. For example, a daily schedule might provide the day it's running on to one of the solids as a config value, and that solid might use that config value to decide what day's data to read.

### Config Schema

Dagster includes a system for gradually-typed, self-describing configuration schemas. For example, you can specify that a particular solid accepts configuration for a particular set of keys, and that values provided for a particular key must be integers. Before executing a pipeline, Dagster will compare the provided run configuration to the config schema for the objects in the pipeline and fail early if they don't match.

Configuration schema helps:

- Catch configuration errors before pipeline execution.
- Make deployed pipelines self documenting, so that it's easy to learn what configuration is required to launch them.

The full range of config types and ways to specify config schema are [documented in the API Reference with examples](/\_apidocs/config).

The most common objects to specify <PyObject module="dagster" object="ConfigSchema" /> for are <PyObject module="dagster" object="SolidDefinition" /> and <PyObject module="dagster" object="ResourceDefinition" /> (see example code in [Configuring a Resource](#configuring-a-resource)).

## Writing a Configurable Solid

This example shows how to write a solid whose behavior is based on values that are passed in via configuration:

```python file=/concepts/configuration/example.py startafter=start_solid_config_schema endbefore=end_solid_config_schema
@solid(
    config_schema={
        # can just use the expected type as short hand
        "iterations": int,
        # otherwise use Field for optionality, defaults, and descriptions
        "word": Field(str, is_required=False, default_value="hello"),
    }
)
def config_example_solid(context):
    for _ in range(context.solid_config["iterations"]):
        context.log.info(context.solid_config["word"])


@pipeline
def config_example_pipeline():
    config_example_solid()
```

## Providing Run Configuration

You can specify the config values in the following ways:

### Python API

You can specify the config values through `run_config` argument to <PyObject module="dagster" object="execute_pipeline" />

```python file=/concepts/configuration/example.py startafter=start_solid_config_good endbefore=end_solid_config_good
def run_good_example():
    return execute_pipeline(
        config_example_pipeline,
        run_config={"solids": {"config_example_solid": {"config": {"iterations": 1}}}},
    )
```

Dagster validates the `run_config` against the `config_schema`. If the values violate the schema, it will fail at execution time. For example:

```python file=/concepts/configuration/example.py startafter=start_solid_config_bad endbefore=end_solid_config_bad
def run_bad_example():
    # This run will fail to start since there is required config not provided
    return execute_pipeline(config_example_pipeline, run_config={})


def run_other_bad_example():
    # This will also fail to start since iterations is the wrong type
    execute_pipeline(
        config_example_pipeline,
        run_config={"solids": {"config_example_solid": {"config": {"iterations": "banana"}}}},
    )
```

### Dagster CLI

The config values can also be in YAML files like:

```YAML file=/concepts/configuration/good.yaml
solids:
  config_example_solid:
    config:
      iterations: 1
```

You can use the Dagster CLI <PyObject module="dagster-pipeline-execute" object="--config" displayText="dagster pipeline execute --config" /> to run a pipeline with one or more YAML files.

### Dagit

You can also edit the config and execute a run in Dagit's [Playground](/concepts/dagit/dagit#playground):

<Image
alt="Config in Dagit"
src="/images/concepts/config-dagit.png"
width={3808}
height={2414}
/>

The config editor on the page comes with typeaheads, schema validation, and schema documentation. You can also click the "Scaffold Missing Config" button to generate dummy values based on the config schema.

## Examples

### Configuring a Resource

You can also configure a <PyObject module="dagster" object="ResourceDefinition" />:

```python file=/concepts/configuration/configured_example.py startafter=start_solid_marker endbefore=end_solid_marker
@resource(config_schema={"region": str, "use_unsigned_session": bool})
def s3_session(_init_context):
    """Connect to S3"""
```

And specify the configurations at runtime via a run config like:

```python file=/concepts/configuration/configured_example.yaml
resources:
  key:
    config:
      region: us-east-1
      use_unsigned_session: False
```

### Passing Configuration to Multiple Solids in a Pipeline

If you want to make a single config value available to multiple solids, you can house the configuration inside a resource and reference that resource from any solid that wants to use it.

```python file=/concepts/configuration/multiple_solids.py
from dagster import ModeDefinition, execute_pipeline, pipeline, resource, solid


@resource(config_schema=str)
def my_str_resource(init_context):
    return init_context.resource_config


@solid(required_resource_keys={"my_str"})
def solid1(context):
    context.log.info("solid1: " + context.resources.my_str)


@solid(required_resource_keys={"my_str"})
def solid2(context):
    context.log.info("solid2: " + context.resources.my_str)


@pipeline(mode_defs=[ModeDefinition(resource_defs={"my_str": my_str_resource})])
def my_pipeline():
    solid1()
    solid2()


execute_pipeline(my_pipeline, run_config={"resources": {"my_str": "some_value"}})
```
