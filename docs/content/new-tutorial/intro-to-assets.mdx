---
title: "Introduction to the Dagster Tutorial and Assets | Dagster Docs"
description: "Learn about the objectives for the Dagster tutorial and about assets"
noindex: True
---

# Introduction to Dagster

Dagster is an orchestrator that's designed for developing and maintaining data assets, such as tables, data sets, machine learning models, and reports.

In this tutorial, you will analyze activity on a popular news aggregation website. Similar to your data pipelines, you will fetch data from the website, clean it up, and build a report that summarizes some findings. We'll then tell Dagster to occassionally update the data and the report, which Dagster calls _assets_.

---

## Introduction to Software-defined assets

Before building a Dagster project, you'll first learn about Dagster's core concept: the Software-defined asset (SDA).

An asset is an object in persistent storage that captures some understanding of the world. Assets can be any type of object, such as:

- A database table or view
- A file, such as in your local machine or blob storage like Amazon S3
- A machine learning model

A Software-defined asset is Dagster's concept that couples an asset to the function and upstream assets that are used to produce its contents.

If you have an existing data pipeline, you likely already have assets.

### Goals

By the end of this section, you will:

- Know what assets are
- Know the power of Software-defined assets
- Know when to use task-based orchestration with assets
- Start to think about what parts of your current pipeline are assets

### Parts of a Software-defined asset

Software-defined assets wrap objects to enable data engineers to do more with them.

As a Dagster user, you're able to build assets in code.

```python file=/intro_tutorial/basics/hackernews/hackernews.py startafter=start_topstories_asset_marker endbefore=end_topstories_asset_marker
@asset(group_name="hackernews", compute_kind="HackerNews API")
def hackernews_topstories(
    context: OpExecutionContext, hackernews_topstory_ids: List[int]
) -> pd.DataFrame:
    results = []
    for item_id in hackernews_topstory_ids:
        item = requests.get(f"https://hacker-news.firebaseio.com/v0/item/{item_id}.json").json()
        results.append(item)

    df = pd.DataFrame(results)

    context.add_output_metadata(
        {
            "num_records": len(df),
            "preview": MetadataValue.md(df.head().to_markdown()),
        }
    )
    return df
```

As shown in the sample asset above, assets are a framework that wraps around your existing Python code and allows you to add more information and metadata about it.

### Building a DAG of assets

Defining multiple assets creates a DAG of what assets depend on other assets. This DAG, viewable in Dagster's web-based UI, helps you to:

- Understand how your assets relate to each other
- Empower you and your teammates to act, learn, and debug your pipelines

Later in this tutorial, we'll walk you through using Dagster's UI to view and materialize assets, shown below.

<Image
alt="An asset graph"
src="/images/tutorial/asset-graph.png"
width={317}
height={514}
/>

### Extending with ops and jobs

Asset-based orchestration may seem like a new way to approach data orchestration, but it is similar to traditional task-based orchestration. Under the hood, assets are a wrapper around Dagster's task-based framework. Therefore, all work done with SDAs can also done with tasks.

Dagster's best practices believe that data engineers should use assets most of the time. However, users are able to use Dagster's Ops and Jobs' task-based framework when assets are not the right fit. Some common situations to use the task-based framework are when you are:

- Sending emails
- Generating assets you do not know of ahead of time

Once you've completed the basic section of this tutorial, the advanced tutorial explains how to create a complex pipeline that uses both assets and Ops and Jobs.

---

## Next steps

In this section, you learned how Software-defined assets are the building blocks of Dagster and the benefits of asset-based pipelines. We also hinted at other concepts you will learn, such as I/O managers, Ops, and Jobs.

Within your current data pipelines, you likely have many assets. Or if you are earlier in your data journey, you might have an understanding of what data your stakeholders need.

When going through this tutorial, think about what benefits you'll be receiving by treating your data as Software-defined assets in Dagster.
