---
title: Testing Assets | Dagster
description: Dagster enables you to unit-test individual assets and graphs of assets
---

# Testing assets

Creating testable and verifiable data pipelines is one of the focuses of Dagster. We believe ensuring data quality is critical for managing the complexity of data systems. Here, we'll cover how to write unit tests for individual assets, as well as for graphs of assets together.

Let's go back to the assets we defined in the [prior section](/tutorial/assets/asset-graph#a-more-complex-asset-graph) and ensure that they work as expected by writing some unit tests.

---

## Testing the nabisco_cereals asset definition

We'll start by writing a test for the `nabisco_cereals` asset definition, which filters the larger list of cereals down to the those that were manufactured by Nabisco.

1. Create a new file and name it `test_complex_asset_graph.py`.

2. At the top of the file, import the `nabisco_cereals` asset:

   ```python
   from complex_asset_graph import nabisco_cereals
   ```

3. To run the function that derives an asset from its upstream dependencies, we can invoke it directly as if it's a regular Python function. Paste the following code at the bottom of the file:

   ```python file=/guides/dagster/asset_tutorial/complex_asset_graph_tests.py startafter=start_asset_test endbefore=end_asset_test
   def test_nabisco_cereals():
       cereals = [
           {"name": "cereal1", "mfr": "N"},
           {"name": "cereal2", "mfr": "K"},
       ]
       result = nabisco_cereals(cereals)
       assert len(result) == 1
       assert result == [{"name": "cereal1", "mfr": "N"}]
   ```

4. Use pytest or your test runner of choice to run the unit tests:

   ```shell
   pytest test_complex_asset_graph.py
   ```

---

## Testing all asset definitions

We'll also write a test for all the assets together. To do that, we can put them in a list and then pass it to the <PyObject object="materialize" /> function. This returns an <PyObject object="ExecuteInProcessResult" /> object, whose methods let us investigate the success or failure of execution, the values produced by the computation, and other events associated with execution.

1. In `test_complex_asset_graph.py`, add `cereal_protein_fractions` and `highest_protein_nabisco_cereal` to the list of imported assets:

   ```python
   from complex_asset_graph import (
      cereals,
      cereal_protein_fractions,
      highest_protein_nabisco_cereal,
      nabisco_cereals,
   )
   ```

2. Add a new line below the imported assets to import `materialize` from `dagster`:

   ```python
   from dagster import materialize
   ```

3. Add the following code to the bottom of the file:

   ```python file=/guides/dagster/asset_tutorial/complex_asset_graph_tests.py startafter=start_all_assets_test endbefore=end_all_assets_test
   def test_cereal_assets():
       assets = [
           nabisco_cereals,
           cereals,
           cereal_protein_fractions,
           highest_protein_nabisco_cereal,
       ]

       result = materialize(assets)
       assert result.success
       assert result.output_for_node("highest_protein_nabisco_cereal") == "100% Bran"
   ```

4. Use pytest or your test runner to run the unit test:

   ```shell
   pytest test_complex_asset_graph.py
   ```

---

## Conclusion

ðŸŽ‰ Congratulations! Having reached this far, you now have a working, tested set of software-defined assets.

Dagster is written to make testing easy in a domain where it has been historically difficult. Refer to the [Testing docs](/concepts/testing) to learn more about testing in Dagster.

What if you want to do more?

- **Automating asset materialization** - This tutorial covered how to manually materialize assets. Dagster can also kick off materializations automatically: on fixed [schedules](/concepts/partitions-schedules-sensors/schedules) or when your [sensor](/concepts/partitions-schedules-sensors/sensors) says to.
- **Partitioning assets** - This tutorial covered assets whose entire contents get re-computed and overwritten with every materialization. When assets are large, itâ€™s common to [partition](/concepts/partitions-schedules-sensors/partitions) them, so that each run only materializes a single partition.
- **Customizing asset storage** - The assets in this tutorial were materialized as pickle files on the local filesystem. [IO managers](/concepts/io-management/io-managers) let you customize how and where assets are stored - e.g. as tables in Snowflake or Parquet files in S3.
- **Non-asset jobs** - This tutorial assumed that your only goal was producing assets. You can also build and run arbitrary [jobs](/concepts/ops-jobs-graphs/jobs#directly-from-ops), on top of the same [op](/concepts/ops-jobs-graphs/ops) and [graph](/concepts/ops-jobs-graphs/graphs) abstractions that underlie assets.
